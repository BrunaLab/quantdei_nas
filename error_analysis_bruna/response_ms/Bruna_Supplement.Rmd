---
title             : "Supplement to Bruna: Fundamental errors of data collection & validation undermine claims of 'Ideological Intensification' made by the National Association of Scholars"
shorttitle        : "Flawed data validation by the NAS"

author: 
  - name          : "Emilio M. Bruna"
    affiliation   : "1,2"
#    address       : "Department of Wildlife Ecology and Conservation, University of Florida, PO Box 110430, Gainesville, FL 32611-0430, USA"
    email         : "embruna@ufl.edu"
    # role:
    #   - Methodology
    #   - Data curation
    #   - Investigation
    #   - Funding acquisition
    #   - Conceptualization
    #   - Formal analysis
    #   - Methodology
    #   - Project administration
    #   - Resources
    #   - Software
    #   - Supervision
    #   - Validation
    #   - Visualization
    #   - Writing original draft

affiliation:
  - id            : "1"
    institution   : "Department of Wildlife Ecology and Conservation, University of Florida, PO Box 110430, Gainesville, FL 32611-0430, USA"
  - id            : "2"
    institution   : "Center for Latin American Studies, University of Florida, PO Box 115530, Gainesville, FL 32611-5530, USA"

authornote: All code and data used in this analysis are available at https://github.com/embruna/quantdei_nas. 

# 
# abstract: |
#   Abstract of the paper.
  
  
  
keywords          : "Up,to,eight,keywords"
wordcount         : "X"

bibliography      : "NAS_response.bib"

floatsintext      : no
figurelist        : yes
tablelist         : no
footnotelist      : no
numbersections    : no
linenumbers       : yes
mask              : no
draft             : no
# replace_ampersands: yes

classoption       : "man, donotrepeattitle" # suppresses title on 1st page of MS
output            : papaja::apa6_pdf
mainfont: Times New Roman
fontsize: 12pt
csl: "science.csl"
fig_caption: yes
keep_tex: yes

header-includes:
  - \raggedbottom
  - \usepackage{endfloat} #[nomarkers] excludes the {insert figure x around here] from main text. The others exclude the list of tables and figures. https://cs.brown.edu/about/system/managed/latex/doc/endfloat.pdf
  - \usepackage{setspace}\singlespacing
  - \usepackage{lineno}
  - \linenumbers
  - \usepackage{tabu}
  - \usepackage{pdflscape}
  - \newcommand{\blandscape}{\begin{landscape}}
  - \newcommand{\elandscape}{\end{landscape}}

---


```{r setup, include = FALSE}
library("papaja")
r_refs("NAS_response.bib")
knitr::opts_chunk$set(echo = FALSE,message=FALSE,warning=FALSE)
library(tidyverse)
library(gridExtra)
library(kableExtra)
library(egg)
library(magick)
```

```{r GlobalOptions, include=FALSE}
options(knitr.duplicate.label = 'allow')
knitr::opts_chunk$set(fig.pos = "H", out.extra = "")
# knitr::opts_chunk$set(fig.pos = 'h')
```
\renewcommand{\arraystretch}{1}
# Data Review and Validation

Below I present a brief overview of the methods used to review the contents of 5 data sets used by Goad and Chartwell to visualize trends in DEI-language use. These data sets can be found in the `'out/twitter'`,`'out/grants'`, and `'out/scholarship'` folders of the NAS Report's Github repository [@goadIdeologicalIntensificationSTEM2023].

1. University Twitter accounts: `tweets_clean.csv`
1. National Science Foundation (i.e., NSF) grants: `nsf_all_grants_summary_data.csv` 
1. National Institutes of Health (i.e., NIH) grants: `nih_parsed_all.fst`
1. Scientific publications indexed in Google Scholar: `google_scholar.fst`
1. Scientific publications indexed in PubMed: `pubmed.fst`   

Although many of these errors are immediately evident by simply scanning their data sets, I also reviewed their data with code written in the R statistical programming language [@rcoreteamLanguageEnvironmentStatistical2020]. This code, which included functions from the `tidyverse` [@wickhamWelcomeTidyverse2019] and `janitor` [@firkeJanitorSimpleTools2021] libraries for filtering, de-duplicating, and summarizing data frames, is available at [@BrunaLabQuantdeiNas] along with `.csv` files of the results. Below I provide summaries and representative examples of the errors revealed by the validation procedures . It is important to emphasize that the error estimates presented are conservative, as the procedures described here are merely a "first pass" using relatively simple methods; more robust validation efforts, for example using keyword co-associations, will almost certainly identify additional errors. 

## _University Twitter accounts_

```{r cached=TRUE, echo = FALSE, warning=FALSE,message = FALSE}
knitr::opts_chunk$set(echo = FALSE)
twitter_notdei<-read_csv("./error_analysis_bruna/validation_output/twitter_notdei.csv",col_types = cols())
twitter_notdei_summary<-read_csv("./error_analysis_bruna/validation_output/twitter_notdei_summary.csv",col_types = cols())

total_tweets_reviewed<-twitter_notdei_summary %>% 
  select(total_tweets_reviewed) %>% 
  slice(1)

total_tweets_clean<-twitter_notdei_summary %>% 
  select(total_tweets_clean) %>% 
  slice(1)

total_tweets_fail<-twitter_notdei_summary %>% 
  summarize(sum(fail_tweets))

min_perc<-round(min(twitter_notdei_summary$perc_fail),2)
max_perc<-round(max(twitter_notdei_summary$perc_fail),2)
```
Goad and Chartwell searched 895 university accounts for over 20 terms they define as DEI-related [@goad2022ideological]. They used the resulting dataset of N = `r total_tweets_clean` tweets (`'tweets_clean.csv'`) to graph the use of the DEI-terms over time. Many of the terms for which they searched, however, have uses and meanings beyond DEI. For instance, "race" could refer to competitions or athletic events, "ally" is a common nickname for "Allison", "justice" is the title used by members of federal or state bench, and introductions are often prefaced by the phrase "it is my privilege to...".   
I reviewed Goad and Chartwell's twitter dataset for tweets that might be using seven of their DEI-related search terms in a non-DEI context. These terms were: "advocacy", "ally", "diversity", "equity", "justice", "privilege", and "race". I first filtered `'tweets_clean.csv'` for all tweets they assigned to a terms (e.g., "race"), then searched this subset of tweets for strings related to non-DEI uses of that term (e.g., "5K", "nascar", "sailing"). To ensure that the resulting tweets were not related to DEI, I eliminated any that included the entire suite of DEI-terms with which Goad and Chartwell conducted their searches (e.g., "racism", "equality", "gender", "social justice", "blm", "equity", see `"validation code"` in [@BrunaLabQuantdeiNas]). Note that this method provides a conservative estimate of any non-DEI tweets included by Goad and Chartwell in there analyses, as it will only capture tweets using the limited suite of non-DEI terms I included. The complete list of filtering strings for each of the 7 DEI-terms I reviewed is in `'twitter_errors.R'`; the complete collection of non-DEI tweets is in `'twitter_notdei.csv'`.   
The seven search terms reviewed comprise `r round(total_tweets_reviewed/total_tweets_clean*100,2)`% of Goad and Chartwell's twitter dataset (N = `r total_tweets_reviewed` tweets). Based on the  conservative validation method described above, at least `r round(((total_tweets_fail/total_tweets_reviewed)*100),2)`% of the tweets for the seven focal terms I reviewed are not DEI-related, with the percentage of irrelevant tweets for a given term ranging from `r min_perc` - `r max_perc`% (Tables 1,2). If there were no additional errors in these or the remaining 14 terms, the overall error rate for the entire data set would be `r round(((total_tweets_fail/total_tweets_clean)*100),2)`%.

## _NIH and NSF grants_ 

```{r cached=TRUE, echo = FALSE, warning=FALSE,message = FALSE}
knitr::opts_chunk$set(echo = FALSE)
nsf_div_grants<-read_csv("./error_analysis_bruna/validation_output/grants_nsf_diversity.csv",col_types = cols())
grant_dupes<-read_csv("./error_analysis_bruna/validation_output/grants_dupes.csv",col_types = cols())


number_nsfdiv<-nrow(nsf_div_grants)

perc_duped_nsf<-grant_dupes %>% filter(agency=="nsf") %>% select(percent_duplicated_rows) 
perc_duped_nih<-grant_dupes %>% filter(agency=="nih") %>% select(percent_duplicated_rows) 
```

Goad and Chartwell also failed to screen for alternative uses of their focal terms when reviewing the grants awarded by NSF and NIH. For example, N = `r number_nsfdiv` of the NSF grants they identify as being DEI-focused when searching with the term "diversity" are actually grants for ecological or evolutionary research on genetic, phylogenetic, or species diversity (see Table 3, `'grants_nsf_diversity.csv'`). They also inflated their sample sizes for the total number of DEI-related grants awarded by NSF and NIH because they failed to account for the mechanism by which agencies transfer funds for to collaborators on successful proposals. A single funded proposal will often be represented in award databases by multiple records because the researchers based at different institutions will be allocated their respective portions of the grant as separate awards. While calculating the total support for DEI-related activities by NSF and NIH requires adding the amount of the individual awards, by not consolidating the different awards for the same project they have inflated their estimates of NSF and NIH grants by `r perc_duped_nsf`% and `r perc_duped_nih`%, respectively. 
 
 
## _Scientific publications in Google Scholar_

```{r cached=TRUE, echo = FALSE, warning=FALSE,message = FALSE}
knitr::opts_chunk$set(echo = FALSE)
gs_dupes<-read_csv("./error_analysis_bruna/validation_output/gs_dupes.csv",col_types = cols())
gs_sources<-read_csv("./error_analysis_bruna/validation_output/gs_sources_all_summary.csv",col_types = cols())
gs_sources_not_stem<-read_csv("./error_analysis_bruna/validation_output/gs_sources_not_stem_summary.csv",col_types = cols())

pm_sources_not_stem<-read_csv("./error_analysis_bruna/validation_output/pm_sources_not_stem_summary.csv",col_types = cols())
pm_dupes<-read_csv("./error_analysis_bruna/validation_output/pm_dupes.csv",col_types = cols())
pm_sources<-read_csv("./error_analysis_bruna/validation_output/pm_sources_all_summary.csv",col_types = cols())
pm_nondei<-read_csv("./error_analysis_bruna/validation_output/pm_nondei_examples.csv",col_types = cols())
gs_nondei<-read_csv("./error_analysis_bruna/validation_output/gs_neurology_examples.csv",col_types = cols())
pubs_dupes_summary<-read_csv("./error_analysis_bruna/validation_output/pubs_dupes_summary.csv",col_types = cols())


```

Finally, Goad and Chartwell sought to identify DEI-related publications in the scientific literature. To do so they searched the repositories Google Scholar, arXiv, Web of Science, and PubMed for DEI-related articles in science, technology, engineering, and mathematics (STEM) journals by using search strings including a STEM-term and one of their DEI-related terms (e.g., "biology diversity"). I reviewed their data from Google Scholar and Pubmed.  
Goad and Chartwell again failed to search their results for duplicate records. The `r sum(pubs_dupes_summary$n_original)-sum(pubs_dupes_summary$n_deduped)` duplicates that remained in these datasets inflated their estimate of DEI-related publications in Google Scholar and PubMed by `r pubs_dupes_summary %>% filter(dataset=="gs") %>% select(perc_inflated)`% and `r pubs_dupes_summary %>% filter(dataset=="pubmed") %>% select(perc_inflated)`%.  They also failed to exclude hundreds of articles that were published in cultural studies, humanities, and legal journals (Table 4), as well as non-DEI articles on topics ranging from impact of the COVID-19 pandemic on the food rationing in Rwanda to workplace interventions for facilitating breastfeeding by working women (see Table 5,`'gs_neurology_examples.csv'`, `'pm_nondei_examples.csv'`.  



# References

::: {#refs custom-style="Bibliography"}
:::

\newpage

<!-- ```{r FigS1, echo=FALSE, message = FALSE, warning=FALSE, fig.align='center', fig.cap="Percentage of irrelevant tweets atrtibuted to seven different DEI search terms. Note that this percentage is a conservative estimate, as it is based on a preliminary review.", fig.fullwidth=TRUE,fig.height = 5,fig.width=5} -->
<!-- twitter_plot<-ggplot(data=twitter_notdei_summary, aes(x=reorder(category,perc_fail),y=perc_fail)) + -->
<!--   geom_bar(stat="identity") + -->
<!--   labs(x="DEI-related Terms", -->
<!--        y="Irrelevant Tweets (%)", -->
<!--        title=" ")+ -->
<!--   scale_y_continuous(breaks=c(0,5,10,15,20,25,30,35,40,45,50), expand = c(0, 0)) + -->
<!--   theme_classic()+ -->
<!--   theme( -->
<!--     # plot.title = element_text(face="bold", size=20,family = "Arial", colour = "black"), -->
<!--         # Sets title size, style, location -->
<!--         # legend.position=c(0.5,0.95), -->
<!--         axis.line.y = element_line(color="black", size = 0.5, lineend="square"), -->
<!--         axis.line.x = element_line(color="black", size = 0.5, lineend="square"), -->
<!--         axis.title.x=element_text(colour="black", size = 14, vjust=-1,hjust=0.5),           #S ets x -->
<!--         axis.title.y=element_text(colour="black", size = 14, vjust=1.5,hjust=0.5),            #S ets y -->
<!--         axis.text.x=element_text(colour="black", size = 10, angle = 0, vjust =0, hjust=0.5), -->
<!--         axis.text.y=element_text(colour="black", size = 10, angle = 0, vjust =0, hjust=0),                          # Sets size and style of labels on axes -->
<!--         # legend.title = element_blank(),                                             # Removes the Legend title -->
<!--         # legend.key = element_blank(),                                              #R emoves the boxes around legend colors -->
<!--         # legend.text = element_text(face="italic", color="black", size=12), -->
<!--         # legend.position = "top", -->
<!--         # legend.direction = 'horizontal', -->
<!--         # legend.key = element_rect(colour = "black"),                              #s ets size and style of labels on axes -->
<!--         # plot.margin = unit(c(1,2,1,1), "cm") -->
<!--         plot.background = element_rect(fill = "white"), -->
<!--         panel.background = element_rect(fill = "white") -->
<!--   ) -->
<!-- twitter_plot -->
<!-- ``` -->

\renewcommand{\arraystretch}{1}


```{r Table1, echo=FALSE,message = FALSE,warning=FALSE}

Table1<-twitter_notdei_summary %>% 
  mutate(perc_fail=round(perc_fail,2)) %>% 
  select(-total_tweets_reviewed,-total_tweets_clean)

names(Table1)<-c("DEI Term","Irrelevant Tweets (N)","Total Tweets (N)","% Irrelevant")

Table1<-knitr::kable(Table1, 
      digits = 2,
      align="ccc",
      format="latex",
      row.names = FALSE,
      booktabs=T,
      longtable=F,
      linesep = "", #removes the blank line after every 5 lines
      caption = "Irrelevant tweets attributed to seven different DEI terms and the total number of tweets for each term in the original dataset. Note that this percentage is a conservative estimate, as it is based on a preliminary review.") %>%
     kable_styling(bootstrap_options = c("hover"),
                 full_width = T,
                 latex_options="scale_down",
                 font_size = 12,
                position = "left")  %>% 
    column_spec(column = 1, width = "7em") %>% 
  column_spec(column = 2, width = "12em") %>% 
    column_spec(column = 3, width = "12em") %>% 
  column_spec(column = 4, width = "12em")

  



Table1
```






<!-- \blandscape -->
<!-- \newpage -->
```{r Table2, echo=FALSE,message = FALSE,warning=FALSE}

Table2<-twitter_notdei %>% 
  group_by(category) %>% 
  slice(1:5) %>% 
  rename("Tweet"="text",
         "Category"="category") %>% 
  mutate(Category = ifelse(row_number()==1, Category, "")) %>% 
  select(Category,Tweet) %>% 
  # mutate(tweet=gsub("[[:punct:]]", "", tweet))  %>% 
 mutate(Tweet=str_sub(Tweet, 1, 110))


Table2$Tweet<-iconv(Table2$Tweet, "latin1", "ASCII", sub="")
# any(grepl("I_WAS_NOT_ASCII", iconv(Table2$Tweet, "latin1", "ASCII", sub="I_WAS_NOT_ASCII"))) 
# %>% 
#   mutate(text=gsub("\\\\", " ", tweet)
#                    
# Table1<-Tables[2]
# Table1<-as.data.frame(Table1)
# Table1<-arrange(Table1,desc(`APC..US..`))


names(Table2)<-c("DEI Term","sample irrelevant tweet")

Table2<-knitr::kable(Table2, 
      digits = 2,
      align="ll",
      format="latex",
      row.names = FALSE,
      booktabs=T,
      longtable=F,
      linesep = "", #removes the blank line after every 5 lines
      caption = "Sample tweets incorrectly attributed to different DEI terms.") %>%
  kable_styling(bootstrap_options = c("hover"),
                full_width = T,
                latex_options="scale_down",
                font_size = 10,
               position = "left") %>% 
  column_spec(column = 1, width = "5em") %>% 
  column_spec(column = 2, width = "50em")

# %>%
#   footnote(number = c("OA Mirror title: Biochimie Open", "OA Mirror title: Micro and Nano Engineering")) %>% add_header_above(c(" " = 1, "Subscription Journal" = 2, "Mirror Journal" = 1))
# tmp<-str_replace(tmp, "Super1", "$^{1}$")
# tmp<-str_replace(tmp, "Super2", "$^{2}$")
# knitr::asis_output(tmp)
Table2
```


<!-- \blandscape -->
<!-- \newpage -->
```{r Table3, echo=FALSE,message = FALSE,warning=FALSE}

Table3<-nsf_div_grants %>% 
  slice(1:50) %>% 
  select(title) %>% 
  rename("Grant Title"="title")  %>% 
  mutate(Sample=row_number()) %>% 
  relocate(Sample,.before=1)
 

Table3$`Grant Title`<-iconv(Table3$`Grant Title`, "latin1", "ASCII", sub="")
# any(grepl("I_WAS_NOT_ASCII", iconv(Table3$`Grant Title`, "latin1", "ASCII", sub="I_WAS_NOT_ASCII"))) 

 #  mutate(category = ifelse(row_number()==1, category, "")) %>% 
 #  select(category,tweet) %>% 
 #  # mutate(tweet=gsub("[[:punct:]]", "", tweet))  %>% 
 # mutate(tweet=str_sub(tweet, 1, 70))

# %>% 
#   mutate(text=gsub("\\\\", " ", tweet)
#                    
# Table1<-Tables[2]
# Table1<-as.data.frame(Table1)
# Table1<-arrange(Table1,desc(`APC..US..`))


# names(Table2)<-c("DEI Term","sample irrelevant tweet")

Table3<-knitr::kable(Table3, 
      digits = 2,
      align="ll",
      format="latex",
      row.names = FALSE,
      booktabs=T,
      longtable=F,
      linesep = "", #removes the blank line after every 5 lines
      caption = "Sample non-DEI grants awarded by the NSF included by searching for the term 'Diversity'. ") %>%
  kable_styling(bootstrap_options = c("hover"),
                full_width = T,
                latex_options="scale_down",
                font_size = 12,
               position = "left") %>% 
  column_spec(column = 1, width = "4em") %>% 
  column_spec(column = 2, width = "50em") 

# %>%
#   footnote(number = c("OA Mirror title: Biochimie Open", "OA Mirror title: Micro and Nano Engineering")) %>% add_header_above(c(" " = 1, "Subscription Journal" = 2, "Mirror Journal" = 1))
# tmp<-str_replace(tmp, "Super1", "$^{1}$")
# tmp<-str_replace(tmp, "Super2", "$^{2}$")
# knitr::asis_output(tmp)
Table3
```














<!-- \blandscape -->
<!-- \newpage -->
```{r Table4, echo=FALSE,message = FALSE,warning=FALSE}
pm_sources_not_stem$Repository<-"PubMed"
gs_sources_not_stem$Repository<-"Google Scholar"
Table4<-bind_rows(gs_sources_not_stem,pm_sources_not_stem) %>% 
  relocate(Repository,.before=1) %>% 
  group_by(Repository) %>% 
  slice(1:20) %>% 
  mutate(Repository = ifelse(row_number()==1, Repository, "")) %>% 
  rename(Source=source,
         N=n) 
  

Table4$Source<-iconv(Table4$Source, "latin1", "ASCII", sub="")
# any(grepl("I_WAS_NOT_ASCII", iconv(Table4$Source, "latin1", "ASCII", sub="I_WAS_NOT_ASCII")))
# %>% 
#   mutate(gsub("[[:punct:]]", "", Title)) 
#  # mutate(tweet=str_sub(tweet, 1, 70))

# %>% 
#   mutate(text=gsub("\\\\", " ", tweet)
#                    
# Table1<-Tables[2]
# Table1<-as.data.frame(Table1)
# Table1<-arrange(Table1,desc(`APC..US..`))


# names(Table2)<-c("DEI Term","sample irrelevant tweet")

Table4<-knitr::kable(Table4, 
      digits = 2,
      align="llll",
      format="latex",
      row.names = FALSE,
      booktabs=T,
      longtable=F,
      linesep = "", #removes the blank line after every 5 lines
      caption = "Sample non-STEM journals and the number of articles from each included in NAS analysis of DEI-focused publications in STEM outlets.") %>%
  kable_styling(bootstrap_options = c("hover"),
                full_width = T,
                latex_options="scale_down",
                font_size = 10,
               position = "left") %>% 
  column_spec(column = 1, width = "8em") %>%
  column_spec(column = 2, width = "50em") %>% 
  column_spec(column = 3, width = "7em") 
  

# %>%
#   footnote(number = c("OA Mirror title: Biochimie Open", "OA Mirror title: Micro and Nano Engineering")) %>% add_header_above(c(" " = 1, "Subscription Journal" = 2, "Mirror Journal" = 1))
# tmp<-str_replace(tmp, "Super1", "$^{1}$")
# tmp<-str_replace(tmp, "Super2", "$^{2}$")
# knitr::asis_output(tmp)
Table4
```




<!-- \blandscape -->
<!-- \newpage -->
```{r Table5, echo=FALSE,message = FALSE,warning=FALSE}

gs_nondei$year<-as.numeric(gs_nondei$year)
pm_nondei$year<-as.numeric(pm_nondei$year)
Table5<-bind_rows(gs_nondei,pm_nondei) %>% 
  select(database,title, year,source) %>% 
  group_by(database) %>% 
  slice(1:10) %>% 
  rename("Repository"="database",
         Title=title,
         Source=source,
         Year=year)  %>% 
  mutate(Repository = ifelse(row_number()==1, Repository, "")) %>% 
  mutate(Title = gsub("[[:punct:]]", "", Title)) 

Table5$Title<-iconv(Table5$Title, "latin1", "ASCII", sub="")
# any(grepl("I_WAS_NOT_ASCII", iconv(Table5$Title, "latin1", "ASCII", sub="I_WAS_NOT_ASCII")))
 # mutate(tweet=str_sub(tweet, 1, 70))

# %>% 
#   mutate(text=gsub("\\\\", " ", tweet)
#                    
# Table1<-Tables[2]
# Table1<-as.data.frame(Table1)
# Table1<-arrange(Table1,desc(`APC..US..`))


# names(Table2)<-c("DEI Term","sample irrelevant tweet")

Table5<-knitr::kable(Table5, 
      digits = 2,
      align="llll",
      format="latex",
      row.names = FALSE,
      booktabs=T,
      longtable=F,
      linesep = "", #removes the blank line after every 5 lines
      caption = "Sample non-DEI publications harvested from PubMed and Google Scholar. ") %>%
  kable_styling(bootstrap_options = c("hover"),
                full_width = T,
                latex_options="scale_down",
                font_size = 10,
               position = "left") %>% 
  column_spec(column = 1, width = "7em") %>%
  column_spec(column = 2, width = "35em") %>% 
  column_spec(column = 3, width = "3em") %>%
  column_spec(column = 4, width = "13em")

# %>%
#   footnote(number = c("OA Mirror title: Biochimie Open", "OA Mirror title: Micro and Nano Engineering")) %>% add_header_above(c(" " = 1, "Subscription Journal" = 2, "Mirror Journal" = 1))
# tmp<-str_replace(tmp, "Super1", "$^{1}$")
# tmp<-str_replace(tmp, "Super2", "$^{2}$")
# knitr::asis_output(tmp)
Table5
```




<!-- \elandscape -->


